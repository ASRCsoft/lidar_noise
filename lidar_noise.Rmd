---
journal: jhm
layout: twocol
title: Wind lidar signal reception as a hidden Markov process
author1: Andrew N. Other
author2: Fred T. Secondauthor
author3: Jeff Friedman
currentaddress: "Current address: Some other place, Germany"
affiliation: "American Meteorological Society,Boston, Massachusetts"
exauthors: 
  - name: William May
    exaffiliation: Atmospheric Sciences Research Center
    correspondingauthor: "American Meteorological Society, 45 Beacon St., Boston, MA 02108."
    email: \email{groupleader@unknown.uu}
  - name: Kara Sulia
    exaffiliation: Atmospheric Sciences Research Center
    currentaddress: "Current address: Some other place, Canada"
  - name: Jeff Friedman
    exaffiliation: Atmospheric Sciences Research Center
    currentaddress: "Current address: Some other place, Canada"
abstract: |
  Wind lidars are widely deployed to measure atmospheric wind speeds. However, wind speed measurements are corrupted by impulse noise when the lidar's laser backscatter is weaker than environmental background noise. We model lidar signal reception as a hidden Markov process that switches between a noise state and a signal state and draw on image processing research to obtain approximate solutions to the model. Using this model we are able to dramatically improve on the current data filtering methods in use for wind lidars.
bibliography: lidar_noise.bib
output:
  bookdown::pdf_book:
    base_format: rticles::ams_article
header-includes:
  - \usepackage{subfig}
  - \usepackage{booktabs}
  - \DeclareMathOperator{\median}{median}
  - \DeclareMathOperator{\filter}{filter}
---

```{r setup, echo=TRUE, include=FALSE}
library(reticulate)
if (file.exists('python_path.txt')) {
  python_path = readLines('python_path.txt')[1]
} else {
  python_path = Sys.which('python3')
}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, cache = TRUE,
                      engine.path = list(python = python_path))
knitr::knit_engines$set(python = reticulate::eng_python)
```

# Introduction

LIDAR, or light detection and ranging, technology uses span a myriad of scientific and intra-scientific disciplines, including, particularly within the earth sciences.  In atmospheric sciences alone, LIDAR is used to detect and measure a plethora of meteorological data, such as temperature, water vapor, boundary layer height, and aerosols \cite[e.g., ][, respectively]{Arshinov:1983,Ismail:1989,Menut:1999,Koch:2004}, among others. As a signal measuring instrument in which measurements are retrieved via backscatter, background noise accompanies data retrievals. As such, lidar instrumentation include noise-filtering software, typically designed by the lidar manufacturer. Such software include X (cite), Y (cite), and Z (cite) methodologies.

Of particular interest to this study is the Leosphere XXXX lidar used primarily to detect retrievals of wind, CNR, and Z. Moreover, the Leosphere lidar retrievals can be used to indirectly determine other atmospheric properties, such as, W, T, and U.  <more background on Leosphere lidar here>.

The Leosphere lidar currently has the XX noise-filtering algorithm built into the data-retrieval software. This methodology filters….<add here the current filtering thresholds>.  It is found that while this methodology serves to provide an acceptable range of retrieved data, the limitations of the aforementioned thresholds leave gaps in more precise retrievals of X, Y, and Z, and also leave behind (relatively obvious) noisy data among what is deemed real data.

To more accurately filter wind measurements, we propose a hidden markov random field model of lidar wind measurements. In the model, the measurements switch between noise and wind states. The recorded CNR and radial wind speed values are generated by a state-dependent random process.

In the wind state, the recorded radial wind speeds and CNR values exhibit spatial and temporal autoregression. To account for this our model requires an estimate of the local radial wind speed and CNR values in the wind state. We turn to impulse noise filtering methods developed in image processing research to obtain these estimates.

We apply this method to data collected by Leosphere lidars used by the University at Albany Atmospheric Sciences Research Center as well as the New York State Mesonet. We then validate the resulting wind estimates against radiosonde wind estimates. The reults show that the resulting measurement accuracy is comparable to that of the Leosphere wind estimates below the planetary boundary layer, and greater than the current Leosphere estimates above the planetary boundary layer.

# Background

<!-- ## Current filtering methods -->

<!-- Current classification strategies for lidar data typically involve a combination of signal strength thresholds and spike filters that leave some valid data incorrectly labeled as noise. Current filtering methods typically work in a two-step process: first a signal strength threshold is applied, which removes most contiguous sections of noise measurements where the signal is consistently low. The threshold is chosen to create a low type I error or false alarm rate. However lowering the false alarm rate implies increasing the type II error rate, so this step generally leaves some valid data incorrectly labeled as noise. -->

<!-- Due to the low false alarm rate most remaining data at this stage is valid. This creates an environment where a spike filter can be applied to remove the remaining extreme outliers. The spike filter can’t be usefully applied to the raw data without the signal threshold due to contiguous sections of noise. -->

<!-- A hidden markov vector autoregressive model that uses both the signal strength and data values simultaneously and incorporates spatial and temporal relationships to improve the measurement classification is proposed. -->


## Markov Random Fields

Markov random fields are commonly used to model image segmentation problems [@li_markov_2009]. The models represent pixels as nodes in a regular network structure. Figure \@ref(fig:networks) shows two common network structures. Each node contains a hidden label which corresponds to an object in an image. Label transition probabilities from a node to a neighboring node are constant throughout the network, thus satisfying Markov properties.

```{r networks, message=FALSE, fig.cap='Standard Markov random field structures. a) Order 1. b) Order 2.', fig.subcap=c('', ''), fig.env="figure*", fig.width=3.17, fig.height=2, fig.ncol=2}
library(igraph)

## the grid of nodes
nodes = matrix(1:100, nrow=10, ncol=10)

make_edges = function(nodes, x_offset, y_offset) {
  if (x_offset >= 0) {
    start_nodes = nodes[1:(nrow(nodes) - y_offset),
                        1:(nrow(nodes) - x_offset)]
    end_nodes = nodes[(y_offset + 1):nrow(nodes),
                      (x_offset + 1):nrow(nodes)]
  } else {
    start_nodes = nodes[1:(nrow(nodes) - y_offset),
                        (1 - x_offset):nrow(nodes)]
    end_nodes = nodes[(y_offset + 1):nrow(nodes),
                      1:(nrow(nodes) + x_offset)]
  }
  cbind(as.vector(start_nodes), as.vector(end_nodes))
}


edges_o1 = rbind(make_edges(nodes, 1, 0),
                 make_edges(nodes, 0, 1))
edges_o2 = rbind(make_edges(nodes, 1, 0),
                 make_edges(nodes, 0, 1),
                 make_edges(nodes, 1, 1),
                 make_edges(nodes, -1, 1))
go1 = graph_from_edgelist(edges_o1, directed=F)
go2 = graph_from_edgelist(edges_o2, directed=F)

grid_layout = layout_on_grid(go1, width = 10, height = 10)

par(mar=rep(0, 4))
plot(go1, layout=grid_layout,
     rescale=FALSE, xlim=c(3.5, 7.5), ylim=c(3.5, 7.5),
     vertex.size=30, vertex.color='gray', vertex.label=NA)

par(mar=rep(0, 4))
plot(go2, layout=grid_layout,
     rescale=FALSE, xlim=c(3.5, 7.5), ylim=c(3.5, 7.5),
     vertex.size=30, vertex.color='gray', vertex.label=NA)
```

Observed pixel values are drawn from label-dependent random distributions. The probability of a label for a given pixel can be calculated as a function of the pixel's values and the label probabilities of neighboring nodes.

For example, neuroimaging researchers use markov random fields to identify brain regions in MRI data, modeling each region as a distinct data generating process with values drawn from a Gaussian distribution. The markov random field incorporates spatial relationships between the voxels to produce more coherent classifications.

Existing methods from image segmentation research can estimate hidden markov random field models without autocorrelated error terms. However markov random field models with autocorrelated error terms are intractable. Therefore to estimate the model we have to remove the autocorrelated error terms.

## Image Denoising

A wide variety of filters for predicting local pixel values are available in image processing research which we could potentially use to estimate local space/time error terms. We choose the median filter due to its robustness to “salt and pepper” noise. Salt and pepper noise in degraded images takes on extreme high (white salt) and low (black pepper) values. Typically the median filter is used to replace salt and pepper noise pixels with a more reasonable value derived from neighboring pixels. Given the extreme variance of radial wind speed noise measurements, methods designed for salt and pepper noise hold promise for dealing with lidar noise.


## New York State Mesonet lidar network

... a new 126-site weather sensing network spanning New York State. Of the 126 sites, all of which include surface measuring instrumentation, 17 are collocated with profiling sites, at which the Leosphere lidar is among the instrumentation suite.

The New York State Mesonet bought 17 lidars as part of a FEMA grant. Before deployment at the chosen profiler locations, the lidars were tested on the roof of the CESTM building at the SUNY Polytechnic Institute. The lidars are usually run in DBS (Doppler Beam Swinging) mode, which records radial wind speeds from a vertical profile and 4 profiles 15 degrees off from vertical in each of the 4 cardinal directions. By combining radial wind speeds from different directions we are able to estimate the u, v, and w components of the wind speed.

The CESTM building also houses the National Weather Service, which releases radiosondes twice a day. 

# Methodology

Because our data has both a space (Range) and time dimension, we model the data noise state as a markov random field

The measurements are modeled as switching between noise and valid measurement states, which are described by distinct data generating processes. Due to local homogeneity of the atmosphere each measurement provides information about the state of neighboring measurements which we encode as a space- and time-switching markov random field. Local homogeneity of the atmosphere also creates a pattern of spatially and temporally autocorrelated error terms in the radial wind speed measurements.

Table \@ref(tab:distributions) shows the distributions assigned to CNR and RWS values in each state.

We use a 2-dimensional median filter to estimate the spatially and temporally autocorrelated error terms and subtract that from the raw radial wind speed values, leaving us with an estimate of the residual error. The residuals can then be modeled as a Gaussian variance-switching process without autocorrelated errors, which allows us to solve the model with existing methods. Figure \@ref(fig:filters) shows the RWS and CNR values before and after filtering.


```{python}
# add the current folder to the import path
import sys
sys.path.append('.')
# import modules
import warnings
import numpy as np
warnings.simplefilter("ignore")
import xarray as xr
import rasppy
from scipy.ndimage import median_filter, gaussian_filter

# get lidar data for LOS==0
lidar = xr.open_dataset('cestm_roof80_20171003.nc')
lidar0 = lidar.rasp.los_format().sel(LOS=0)
lidar0.swap_dims({'scan': 'Time'})

# apply filters
lidar0['filtered_RWS'] = (lidar0['RWS'].dims, median_filter(lidar0['RWS'], size=(7, 59)))
lidar0['filtered_CNR'] = (lidar0['CNR'].dims, gaussian_filter(lidar0['CNR'], sigma=(1, 2)))

# organize for R
rws = lidar0['RWS'].values
frws = lidar0['filtered_RWS'].values
cnr = lidar0['CNR'].values
fcnr = lidar0['filtered_CNR'].values
times = lidar0.coords['Time'].values
ranges = lidar0.coords['Range'].values
```

```{r filters, message=FALSE, fig.cap='Raw and filtered CNR and RWS values for October 3rd, 2017. a) Raw RWS values. b) Filtered RWS values. c) Raw CNR values. d) Filtered CNR values.', fig.subcap=c('', ''), fig.env="figure*", fig.width=3.17, fig.height=2, fig.ncol=2}
library(reshape2)
library(ggplot2)
library(scales)
library(viridis)

# get the data from python
rws_df = melt(py$rws)
rws_df$Range = py$ranges[rws_df$Var1]
rws_df$Time = py$times[rws_df$Var2]
ggplot(rws_df, aes(x=Time, y=Range, fill=value, color=value)) + geom_tile() +
  scale_x_datetime('Hour [UTC]', date_labels='%H', expand = c(0, 0)) +
  scale_y_continuous('Range [m]', expand = c(0, 0)) +
  scale_fill_gradient2('RWS [m/s]', low=muted("blue"), high=muted("red"), limits = c(-5,5), oob=squish) +
  scale_color_gradient2('RWS [m/s]', low=muted("blue"), high=muted("red"), limits = c(-5,5), oob=squish)

frws_df = melt(py$frws)
frws_df$Range = py$ranges[frws_df$Var1]
frws_df$Time = py$times[frws_df$Var2]
ggplot(frws_df, aes(x=Time, y=Range, fill=value, color=value)) + geom_tile() +
  scale_x_datetime('Hour [UTC]', date_labels='%H', expand = c(0, 0)) +
  scale_y_continuous('Range [m]', expand = c(0, 0)) +
  scale_fill_gradient2('RWS [m/s]', low=muted("blue"), high=muted("red"), limits = c(-5,5), oob=squish) +
  scale_color_gradient2('RWS [m/s]', low=muted("blue"), high=muted("red"), limits = c(-5,5), oob=squish)

cnr_df = melt(py$cnr)
cnr_df$Range = py$ranges[cnr_df$Var1]
cnr_df$Time = py$times[cnr_df$Var2]
ggplot(cnr_df, aes(x=Time, y=Range, fill=value, color=value)) + geom_tile() +
  scale_x_datetime('Hour [UTC]', date_labels='%H', expand = c(0, 0)) +
  scale_y_continuous('Range [m]', expand = c(0, 0)) +
  scale_fill_viridis('CNR [dB]', limits=c(-35, -10), oob=squish) +
  scale_color_viridis('CNR [dB]', limits=c(-35, -10), oob=squish)

fcnr_df = melt(py$fcnr)
fcnr_df$Range = py$ranges[fcnr_df$Var1]
fcnr_df$Time = py$times[fcnr_df$Var2]
ggplot(fcnr_df, aes(x=Time, y=Range, fill=value, color=value)) + geom_tile() +
  scale_x_datetime('Hour [UTC]', date_labels='%H', expand = c(0, 0)) +
  scale_y_continuous('Range [m]', expand = c(0, 0)) +
  scale_fill_viridis('CNR [dB]', limits=c(-35, -10), oob=squish) +
  scale_color_viridis('CNR [dB]', limits=c(-35, -10), oob=squish)
```


```{r distributions}
text_tbl = data.frame(RWS=c('$N(\\median_i, \\sigma^2)$', 
                            '$U(rws_{min}, rws_{max})$'),
                      CNR=c('$N(\\filter_i, \\sigma^2)$',
                            '$N(\\mu_{noise}, \\sigma^2_{noise})$'),
                      row.names=c('Wind', 'Noise'))
knitr::kable(text_tbl, booktabs=T, escape = F,
  caption = 'RWS and CNR distributions in different states.')
```


# Validation

We follow the method outlined in @kumer_comparison_2014 to compare wind lidar estimates to radiosonde wind speed estimates. They compare correlations of wind speed and wind direction from two types of lidars with measurements from a radiosonde launched from a site 2 kilometers away. Because correlations depend on the height of the measurement, they calculate correlations independently for different heights.

We plot Pearson correlation coefficients in figure \@ref(fig:corr). Our results for the CNR threshold method closely match @kumer_comparison_2014 results for the WindCube 100S, which also uses a CNR threshold to filter data. In particular, we find that at lower altitudes the correlation is weaker, at about $R=.9$, possibly due to swinging motions of the radiosonde sensor. We also observe a drop in the correlation around 1300m, around the top of the cloud level, where valid measurements are often interspersed with noise. kumer_comparison_2014 et al. do not report correlations above 2500m. At these high ranges we record another drop in correlation, possibly due to the radiosonde drifting away from the CESTM building.

The hidden markov random field wind correlations are similar, with the exception that the sharp dips in correlations (that we hypothesize are due to valid measurements interspersed with noise) do not appear. The results suggest that data filtered with the hidden markov random field is comparable in quality to data filtered with the CNR threshold method when only small amounts of noise are present.

```{r corr, fig.cap='Pearson correlation of lidar horizontal wind speeds and radiosonde wind speeds at different heights.', fig.width=3.17, fig.height=2.5}
library(reshape2)
library(ggplot2)

cnr_df = read.csv('data/cnr_stats.csv')
hmrf_df = read.csv('data/hmrf_stats.csv')
ranges = seq(100, 3000, by=25)

corr_df = data.frame(Range=ranges, CNR=cnr_df$corr_u, HMRF=hmrf_df$corr_u)
lcorr = melt(corr_df, id.vars='Range', variable.name='Method',
             value.name='Correlation Coefficient')
names(lcorr)[1] = 'Range [m]'
ggplot(lcorr, aes(x=`Range [m]`, y=`Correlation Coefficient`, color=Method)) +
  geom_line() + scale_color_discrete('Method:') + theme(legend.position="bottom")
```


# Application to lake wind effect

something about lakes and winds


# AMS formatting notes

## Secondary headings {-}

Secondary headings labeled with letters are formatted using the `## Secondary headings {-}` for a single subsection within a section or `## Secondary headings` for multiple subsections within one section.

### Tertiary headings {-}

Tertiary headings are formatted using the `### Tertiary headings {-}` for single a subsubsection within a subsection or `### Tertiary headings` for multiple subsubsections within a subsection. 

\paragraph*{Quaternary headings}
Quaternary headings are formatted using the `\paragraph*{Quaternary headings}` for a single paragraph within a subsubsection or `\paragraph{Quaternary headings}` for multiple paragraphs within a subsection.

# Citations

<!-- Citations to standard references in text should consist of the name of the author and the year of publication, for example, @poe12 or [@poe12;@alexander:2002;@Gershunov2012] using the appropriate `@key` or `[@key]` commands, respectively. A variety of citation formats can be used with the natbib package; however, the AMS prefers that authors use only the `@key` and `[@key]` commands. References should be entered in the references.bib file. For a thorough discussion of how to enter references into the references.bib database file following AMS style, please refer to the **AMS_Refs.pdf** document included in this package. -->

# Formatting math

The following sections will outline the basic formatting rules for mathematical symbols and units.  In addition, a review of the amspaper.tex file will show how this is done with the use of \LaTeX\ commands.  The AMS template provides the American Mathematical Society math, font, symbol, and boldface packages for use in math mode.

## Mathematical symbols

Symbols must be of the same font style both in text discussion and in displayed equations or terms (and figures should be prepared to match). Scalar single-character symbols are set italic, Greek, or script. Examples are $u$, $L$ [note that $\upsilon$ (Greek upsilon) is used instead of *v* (italic "vee") to avoid confusion with $\nu$ (Greek nu) often used for viscosity; this is handled automatically when in \LaTeX\ math mode], $w$, $x$, $y$, $z$, $f$, $g$, $r$, indices such as $i$ or $j$, and constants such as $C_D$, $k$, or $K$. Multiple-character scalar variables, abbreviations, nondimensional numbers, and acronyms for variables are set regular nonitalic: $\mathrm{LWC}$, $\mathrm{Re}$, $\mathrm{Ro}$, $\mathrm{BT}$, $\mathrm{abs}$, $\mathrm{obs}$, $\mathrm{max}$, $\mathrm{min}$, $\mathrm{Re}$/$\mathrm{Im}$ (real/imaginary), etc. For vectors, use boldface nonitalic Times Roman as in $\mathbf{V}$, $\mathbf{v}$, or $\mathbf{x}$, and $\mathbf{i}$, $\mathbf{j}$, and $\mathbf{k}$ unit vectors. Do not use the \LaTeX\ $\backslash vec$ command to denote vectors. For matrix notation, use nonitalic boldface Arial (or sans serif) font as in $\pmb{\mathsf{A}}$, $\pmb{\mathsf{B}}$, or $\pmb{\mathsf{M}}$. Note that you will need to use the $\backslash$pmb command for boldface sans serif; the $\backslash$bm command will not work. All mathematical operator abbreviations/acronyms are set lowercase regular Roman font, except $O$ (on the order of): $\sin$, $\cos$, $\tan$, $\tanh$, $\mathrm{cov}$, $\Pr$ (for probability; note same as Prandtl number), $\mathrm{const}$ (for constant), $\mathrm{c.c.}$ (complex conjugate).

## Units

Units are always set on a single line with a space separating the denominator, which is set with a superscript $-1$, $-2$, and so on, rather than using a slash for "per." Examples are g kg$^{-1}$, m$^2$ s$^{-1}$, Wm$^{-2}$, g m$^{-3}$, and m s$^{-1}$ (note that ms$^{-1}$ is the unit for "per millisecond").

## Equations

Brief equations or terms set inline in text must be set as a single-line expression because page proofs are not double spaced, for example, $\rho^{-1}p/x$ or $(1/{\rho})p/x$ or $(a-b)/(c+d)$; that is, use a superscript $-1$ for the denominator. In case of a more complicated term or equation, it should be set as an unnumbered display equation, such as

$$
x=\frac{2b\pm\sqrt{b^{2}-4ac}}{2c}.
$$

Otherwise, numbered display equations can be entered using the appropriate equation command, such as 

\begin{equation}
x=\frac{2b\pm\sqrt{b^{2}-4ac}}{2c}.  
\end{equation}

Lists of equations are punctuated as written English, and commas, semicolons, and periods are placed where appropriate. Conjunctions such as "and", "while", "when", or "for" are also typically placed before the final element in a mathematical phrase, as befits the intended mathematical meaning.  

## Figures and tables

The AMS prefers that all figures and tables are placed **at the end of the document** prior to submission. A list of tables and a list of figures will appear near the end of the PDFfile, before the actual tables and figures. These lists are necessary for submission.

For appendix figures and tables, special commands are needed to manually change the numbering to ensure that each appendix figure or table is numbered as part of the respective appendix and not as a continuation of the main paper. Use the command `\appendcaption{}` instead of the usual `caption{}` to adjust the  numbering; for example, for Table A1, you would use the command `\appendcaption{A1}`.

Note that the normal `\ref{}` command cannot be used to cite appendix figures and tables as the numbering will be incorrect. Callouts for appendix figures and tables in the text will need to be written out as plain text, for example, Fig. A1 and Table A1.

### Figures

The insertion of a sample figure (Fig. \ref{f1})  
and caption is given below (in the .tex document) and at the end of the document. Standard figure sizes are 19 (one column), 27, 33, and 39 (two columns) picas.

<!-- \begin{figure}[h] -->
<!--  \centerline{\includegraphics[width=19pc]{figure01.pdf}} -->
<!--   \caption{Enter the caption for your figure here.  Repeat as -->
<!--   necessary for each of your figures.}\label{f1} -->
<!-- \end{figure} -->


### Tables
Each table must be numbered, provided with a caption, and mentioned specifically in the text. 
See below (in the .tex document) and at the end of the document for the formatting of a sample table (Table
\ref{t1}).

\begin{table}[h]
\caption{This is a sample table caption and table layout.}\label{t1}
\begin{center}
\begin{tabular}{ccccrrcrc}
\topline
$N$ & $X$ & $Y$ & $Z$\\
\midline
 0000 & 0000 & 0010 & 0000 \\
 0005 & 0004 & 0012 & 0000 \\
 0010 & 0009 & 0020 & 0000 \\
 0015 & 0016 & 0036 & 0002 \\
 0020 & 0030 & 0066 & 0007 \\
 0025 & 0054 & 0115 & 0024 \\
\botline
\end{tabular}
\end{center}
\end{table}

\acknowledgments
Keep acknowledgments (note correct spelling: no e between the g and m) as brief as possible. In general, acknowledge only direct help in writing or research. Financial support (e.g., grant numbers) for the work done, for an author, or for the laboratory where the work was performed is best acknowledged here rather than as footnotes to the title or to an author's name. Contribution numbers (if the work has been published by the author's institution or organization) should be included as footnotes on the title page,
not in the acknowledgments.

Please use The authors thank \ldots rather than The authors would like to thank \ldots.

The author thanks Mats Dahlgren for version one of \textsf{achemso}, and Donald Arseneau for the code taken from \textsf{cite} to move citations after punctuation. Many users have provided feedback on the class, which is reflected in all of the different demonstrations shown in this document.

\appendix[A] 

\appendixtitle{Title of Appendix}

## Appendix section

The AMS template allows authors to format an unlimited number of appendixes. To format a single appendix, use the `\appendix` command with no additional argument. Otherwise, add the appropriate one-letter argument to the `\appendix` command (e.g. `\appendix[A]`, `\appendix[B]`, `\appendix[C]`, etc.) corresponding to the appropriate appendix. 

The title of the appendix can be formatted using the `\appendixtitle{} ` command. The `##` , `###` and `\paragraph` commands are used to create sections within the appendix. (Note that the appendix title takes the place of `#` in the appendix, so the first section should begin with `##` instead of `#`.)

Equations are automatically numbered appropriately for each appendix. Here is an example of the first equation in appendix A, automatically labeled (\ref{eq:1}): 

\begin{equation}
\label{eq:1}
x=\frac{2b\pm\sqrt{b^{2}-4ac}}{2c}.  
\end{equation}

For appendix figures and tables, special commands are needed to manually change the numbering to ensure that each appendix figure or table is numbered as part of the appendix and not as a continuation of the main paper. Use the command `\appendcaption{}` instead of the usual `\caption{}` to adjust the numbering; for example, for Table A1, you would use the command `\appendcaption{A1}`. In-text callouts for each appendix figure and table will need to be written as plain text;the usual `\ref{}` command cannot be used.

# References {-}
\bibliography{references}

\begin{table}
\appendcaption{A1}{Here is the appendix table caption.}
\centering
\begin{tabular}{ccc}
\topline
$1$ & $2$ & $3$ \\
\midline
a&b&c \\
d&e&f \\
\botline
\end{tabular}
\end{table}

\begin{figure}
\centerline{(illustration here)}
\appendcaption{A1}{Here is the appendix figure caption.}
\end{figure}

\begin{figure}
\centerline{(illustration here)}
\appendcaption{B1}{Here is the appendix figure caption.}
\end{figure}
